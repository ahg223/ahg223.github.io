---
title: "Machine Learning"
excerpt: "ROC 커브"

categories:
  - ModernCS
tags:
  - ModernCS
  - MachineLearning
---

## 인공신경망(deep learning이전의 전통적인) 일반적인 문제점
단층퍼셉트론의 xor문제 ->다층퍼셉트론 등장, 학습방법?->오류역전파개념등장 ->시그모이 드함수사용하면 히든레이어많아질수록 가중치계산 안되는데?(gradient vanishing) ->초기 값 바꾸면 잘되는경우도.. 딥러닝 등장 -> 현재는 히든레이어에서 ReLU함수 사용gradient vanishing해결

##  deep learning 계열의 혁신의 근간
컴퓨팅 파워, 특히 GPU를 이용한 고속처리가 가능해지고, 빅데이터 시대가 오면서 딥러닝이
실용적으로 쓰일 수 있게 되었다고 생각합니다. 

## ROC 커브

<img width="449" alt="스크린샷 2019-11-14 오후 9 46 42" src="https://user-images.githubusercontent.com/34998051/68858371-4111e700-0728-11ea-8709-0ffb8c8d5b2e.png">  

여러 카테고리 중 데이터가 어디에 속할지 예측하는 것을 '분류'문제라고 하는데, ROC 커브 는 이러한 분류 문제에 대한 모델을 평가할 때 사용하는 시각화 방법입니다.
ROC 커브를 설명하려면 먼저 몇 가지 용어들을 정의해야 합니다.
분류 모델에서 정확히 분류된 비율을 정확도(Accuracy)라 하는데, 그 중에서도 정확히 분류 된 1의 비율(실제 1인 값들 중 모델이 1이라고 예측한 비율)을 민감도(Sensitivity) 혹은 재현 율(Recall)이라 하고, 정확히 분류된 0의 비율(실제 0인 값들 중 모델이 0이라고 예측한 비율) 을 특이도(Specificity)라고 합니다.
여기서 '1'은 보통 관심의 대상이 되는, 더 중요한 클래스를 의미합니다.(양성)
   
 이 재현율(Recall)과 특이도(Specificity) 사이에는 트레이드오프 관계가 있습니다.
양성을 잘 잡아낸다면 그만큼 음성을 양성으로 잘못 예측할 가능성도 높아지기 때문입니다.
ROC 커브는 이 트레이드오프 관계를 표현하기 위한 지표로 x축의 특이도에 대한 y축의 재현 율을 표시합니다.
ROC커브를 그리기 위해 먼저 1로 예측할 확률에 따라 가장 1이 되기 쉬운 것부터 레코드를 정렬하고, 정렬된 순서대로 점증적으로 특이도와 재현율을 계산하면 됩니다.
이 ROC 곡선 아래의 면적(Area Underneath the Cure, AUC)을 이용하여 분류모델의 성능을 비교할 수 있습니다. AUC가 1이라면 0을 1로 잘못 예측하는 경우 없이 1을 정확히 분류하는 완벽한 분류기를 의미합니다. 최악의 경우는 ROC곡선이 대각선으로 나타나는 경우로 AUC 가 0.5가 됩니다
