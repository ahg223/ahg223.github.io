---
title: "Data Statistics"
excerpt: "bootstrap, 비모수적 모델링, 베이지안과 프리퀀티스트, 검정력"

categories:
  - ModernCS
tags:
  - ModernCS
  - DataScience
---

## 통계에서 사용되는 bootstrap의 의미
부트스트랩이란 모집단에 대해 무작위로 표본 데이터를 반복적으로 복원 추출하는 것입니다 (= Random sampling을 중복을 허용하며 반복적으로 수행). 만약 데이터를 수집했던 확 률변수의 정확한 분포를 모르는 경우, 측정된 통계치의 신뢰도를 가늠할 방법이 없습니다. 이 때 부트스트랩을 사용하면 측정된 값의 신뢰도를 구할 수 있습니다.   

그 외에 기계학습에서 부트스트랩이 쓰이는 경우에 대해서 말씀드리자면,  첫째로 학습 데이터 내에 분포가 한 쪽으로 편향된 경우, 예를 들어 사과가 100개가 들어있고 오렌지가 1만개가 들어있는 데이터에 대해 사과인지 오렌지인지 분류한다고 할 때, 무조건 오렌지로 분류하도록 해도 정확도가 99%가 되어 버립니다. 이런 문제를 피하기 위해 부트 스트랩을 통해 사과와 오렌지가 적절하게 섞여있는 새로운 데이터 셋을 만들 수 있습니다. (예를 들어 사과 100개 중 30개, 오렌지 1만개 중 30개씩을 무작위로 뽑는 과정을 수 회 반복 하여 새로운 데이터 셋을 생성)  

또 데이터 셋이 부족할 경우, overfitting 등의 문제가 발생할 수 있는데 역시 부트스트랩을 통해 데이터 셋의 크기를 늘리면 이를 해결하는데 도움이 될 수 있습니다. 그리고 이를 ‘bagging’이라고 합니다.  

## 모수가 매우 적은 (수십개 이하) 케이스 예측 모델
<img width="449" alt="스크린샷 2019-11-14 오후 9 07 20" src="https://user-images.githubusercontent.com/34998051/68855958-c0042100-0722-11ea-9de1-dc3602f66fe6.png">  

즉 비모수적 방법을 사용해야 합니다.
모수적, 비모수적에 따라 분류한 예측 방법들은 다음과 같습니다.  
- 모수적 모델: 회귀모델, 로지스틱회귀모델, 1차/2차 판별모델
- 비모수적 모델: 의사결정나무, 랜덤포레스트, K-최근접이웃
- 세미보수적 모델: 인공신경망, 서포트벡터머신

## 베이지안과 프리퀀티스트

<img width="449" alt="스크린샷 2019-11-14 오후 9 09 09" src="https://user-images.githubusercontent.com/34998051/68856089-0194cc00-0723-11ea-8782-a3f5cf16afbe.png">  

A와 B가 담긴 바구니에서 A를 꺼낼 확률은 7/10. B를 꺼낼 확률은 3/10이라고 합시다. 그리고 A라는 바구니에서는 흰 공을 2/10, 파란 공을 8/10의 확률로 꺼낼 수 있고, B라는 바구니에서는 흰 공을 9/15, 파란 공을 6/15의 확률로 꺼낼 수 있다고 봅시다.  

어떤 이유에 의해서 흰 공이 뽑혔는데 우린 이 공이 어디서 뽑혔는지 모릅니다. 이 때 이 흰
공이 어디서 뽑혔는지 추정해보기로 합시다.  

A 바구니에서는 흰 공이 뽑힐 확률이 2/10이고 B 바구니에서는 9/15이므로 B 바구니에서 뽑 혔을 확률이 높아 보입니다. 때문에 B 바구니에서 뽑혔을 것이라는 추정은 어느 정도 타당해 보입니다. -> 프리퀀티스트의 입장  

그러나 A 바구니, B 바구니에서 공을 꺼내기 전에 A인지 B인지 결정될 확률이 존재합니다. 이 확률이 분명 결과에 영향을 미칠 것 같습니다. 이 A인지 B인지 결정될 확률이 사전 확률입 니다. 흰 공이 뽑혔을 때 이 공이 A에서 뽑혔는지 B에서 뽑혔는지에 대한 확률이 사후 확률이 됩니다. 이 사후 확률을 구하면 어떤 확신(A에서 뽑혔다 혹은 B에서 뽑혔다)에 대한 확률(또 는 신뢰도)를 얻을 수 있고 이를 토대로 판단을 합니다. -> 베이지안 입장)

## 검정력(statistical power)

검정력(Statistical power)는 대립가설이 사실일 때, 이를 사실로서 결정할 확률이다. 검정 력이 90%라고 하면, 대립가설이 사실임에도 불구하고 귀무가설을 채택할 확률(2종 오류, β error)의 확률은 10%이다. 다르게 설명하자면 대립가설 하의 a = a1에서 귀무가설을 기각시 킬 확률을 a = a1에서의 검정력이라고 말한다. 검정력이 좋아지게 되면, 2종 오류(β error)를 범할 확률은 작아지게 된다. 따라서 검정력은 1-β과 같다.  

특히 실험에서 유의한 차이를 통계적으로 유의하다고 결론 내기 위해서는 충분한 검정력을 지녀야 한다. 검정력 분석은 자료를 모으기 전후 모두 가능하다. 연구 실험 전에 검정력 분석 을 하는 경우는 실험에서 얻어야 할 적절한 통계적 표본크기(sample size)를 결정할 수 있도록 한다.  

<부연 설명>
귀무가설(H0)이란 관습적이고 보수적인 주장, 차이가 없다, 0이다 등의 우리가 타파하고자 하는 주장  
대립가설(H1)이란 입증하려는 주장, 차이가 있음을 통계적 근거를 통해 입증하고자 하는 주장  
유의수준(알파a)이란 오류를 허용할 범위  
유의확률(p-value)이란 대립가설이 틀릴 확률  
유의확률이 유의수준보다 작으면 해당 귀무가설을 기각(타파)할 수 있으며 대립가설을 채택할 수 있다  
검정력이란 p-value의 반대 개념  

## missing value가 있을 경우
경우에 따라 다르지만 대부분의 경우 결측치를 없애는 것(결측치를 채우는 것이 아님)이 필요할 것입니다. 결측치가 존재하면 많은 함수의 경우 제대로 작동하지 않기 때문에 제대로 된 분석이 어려워집니다. (결측치가 없는 경우: mean([1, 3, 5]) = 3, 결측치가 있는 경우: mean([NA, 3, 5]) = NA, 즉 결측치가 있으면 결측치가 결측치를 낳는 불행한 결과를 야기)  

결측치를 없애는 방법으로 몇 가지가 존재합니다.
첫째는 결측치가 포함된 데이터 행이나 컬럼을 제거해버리는 것입니다. 다만 너무 많은 행이 나 컬럼에 결측치가 포함되어 있다면 그만큼 데이터 손실을 야기합니다.
       
둘째는 적절한 값으로 결측치를 채워주는 것입니다. 경우에 따라서는 결측치가 어떤 것을 의 미하는 경우도 있습니다. 이럴 경우 결측치를 해당 의미에 맞게 채워줘야합니다. 만약 그런 것이 아니라면 관련 있는 변수의 특성을 파악하여 이를 토대로 결측치를 채워주거나 단순히 특정한 값, 혹은 평균이나 중간값을 채워줄 수도 있습니다.  
