---
title: "Deep Learning"
excerpt: "Sigmoid vs ReLU, Non-Linearity, Gradient Descent, Training 세트와 Test 세트"

categories:
  - ModernCS
tags:
  - ModernCS
  - DeepLearning
---

## 볼츠만 머신
볼츠만 머신 : 볼츠만의 확률과 엔트로피 개념 수식이 구현된 신경망에서 비슷하다 붙인 이름.
* local minimum에 갇혀 global minimum으로 가지 못하는 경우에 있어, 현재 최솟값에 서 머무르지 않고(기울기가 작아지는 점에 머무르지 않고), 간간히 최솟값에서 커지는 움직임(기울기가 커지는 움직임)을 보이는 것이다.  
* 쉽게 말해 cost가 0이 되는 방향으로 진행되는 학습에서 cost가 증가하는 방향으로도 가끔씩 학습이 된다는 뜻이다.  

## Sigmoid vs ReLU 
Sparsity(a<=0)
벡터를 표시하는 값들 중에 0이 많은 수를 차지한다는 것. 즉, 값이 비어있다. 반대는 dense 한 경우  
a가 0보다 작을 때 값이 0을 갖게된다. == sparsity 하다.  
dense한 경우(sigmoid) 보다 연산량을 월등히 줄여준다.  
Vanishing Gradient(a>0)  
sigmoid의 gradient는 x의 절댓값이 증가하는 만큼 작아지게 되는 것에 비해, ReLU의 역함 수는 1이므로 ReLU의 경우에 gradient로 상수값을 갖게된다. 일정한 gradient 값은 빠르게 학습하는 것을 도와준다.  

  <img width="499" alt="스크린샷 2019-11-14 오후 10 28 52" src="https://user-images.githubusercontent.com/34998051/68861075-2478ad80-072e-11ea-9dfa-b24ee9000e86.png">

동그라미 친 부분이 a>0인 경우의 ReLU그래프라고 생각하면 쉽다.  
  
### Non-Linearity라는 말의 의미와 그 필요성은?
비선형성. 활성화 함수(activation function)에서는 주로 비선형 함수를 사용한다.
선형함수인 h(x)=cx를 활성화함수로 사용한 3층 네트워크를 떠올려 보세요. 이를 식으로 나 타내면 y(x)=h(h(h(x)))가 됩니다. 이는 실은 y(x)=ax와 똑같은 식입니다. a=c3이라고만 하면 끝이죠. 즉, 은닉층이 없는 네트워크로 표현할 수 있습니다. 뉴럴네트워크에서 층을 쌓는 혜 택을 얻고 싶다면 활성화함수로는 반드시 비선형 함수를 사용해야 합니다. - "밑바닥부터 시 작하는 딥러닝"  

데이터에 대해 분석, 회귀 등을 할 때 데이터 분포에 맞게 경계를 잘 그려준다면 좋은 성능을 가진 모델링을 했다고 할 수 있다. 데이터의 복잡도가 높아지고 차원이 높아지면 데이터의 분 포는 단순 선형이 아닌 비선형 형태를 띄게된다. 이 데이터를 단순히 1차원으로 표현할 수 없 기 때문에 비선형이 중요하다.  

###  ReLU로 어떻게 곡선 함수를 근사하나?  

a<=0 인 부분은 0, a>0 인 부분은 a로 출력되는 그래프는 결합 구간을 보았을 때 Non- Linearity한 성질을 가지게 된다. 학습 과정에서 BackPropagation(역전파, 오차 결과값을 input 방향으로 보내며 가중치를 재업데이트 하는 것) 할 때에 모델이 데이터에 적합하도록 fitting 된다. ReLU가 출력층과 멀리 있는 layer 까지 전달되기 때문에 데이터에 적합하도록 fitting이 잘 되게 되고, 이것으로 곡선 함수에 근사하도록 만들어진다.  

### ReLU의 문제점은?  

입력값이 0보다 작을 때 함수 미분값이 0이 된다. 이것을 보완하기 위해 LeakyReLU를 사용
한다.

### Bias는 왜 있는걸까?  

Bias(편향)은 모델이 데이터에 잘 fitting되기 위해서 평행이동 하는 역할. 데이터를 2차원으 로 표현할 때, 모든 데이터가 원점기준은 아닐 수 있다. 이 경우 Bias를 이용하여 모델을 평면 상 이동할 수 있고, 이 경우 Bias 또한 학습한다.

## Gradient Descent
경사하강법. 1차 근사값 발견용 최적화 알고리즘이다. 비용 함수의 기울기(경사)를 구하여 기
울기가 낮은 쪽으로 계속 이동시겨 극값에 이를 때 까지 반복시키는 것이다.  

### Gradient를 써야하는 이유?
어떤 함수를 지역적으로 선형근사하거나, 함수의 극점(최댓값, 최솟값 지점)을 찾는 용도로 활용될 수 있다.  
어느 함수가 감소하는 가장 빠른 방향이라는 점.  
가로축 : W(1차 함수의 기울기), 세로축 : Cost  
<img width="499" alt="스크린샷 2019-11-14 오후 10 30 32" src="https://user-images.githubusercontent.com/34998051/68861188-60137780-072e-11ea-9b74-668f00504632.png">

 
실제 그래프는 어떻게 그려질까? 여러개의 local minimum을 가진 비선형 함수를 가질 것.  

### GD 중에 때때로 Loss가 증가하는 이유는?  

local minimum에 갇혀 빠져나오지 못하는 경우가 발생할 수 있기 때문에 loss가 증가하는 방향으로 gradient가 변화할 수 있다.  

### 중학생이 이해할 수 있게 더 쉽게 설명 한다면?  
<img width="499" alt="스크린샷 2019-11-14 오후 10 30 45" src="https://user-images.githubusercontent.com/34998051/68861200-673a8580-072e-11ea-8789-6d651822a207.png">
위와 같은 그래프에서 우리가 가야하는 방향은 global minimum 인데 반해 현재 local minimum에 갇혀있다. 이것을 탈출하려면 loss가 좀 증가하더라도 크게 움직여 다른 방향으 로 움직여야한다.
 
### Back Propagation에 대해서 쉽게 설명 한다면?
<img width="499" alt="스크린샷 2019-11-14 오후 10 32 49" src="https://user-images.githubusercontent.com/34998051/68861337-b1bc0200-072e-11ea-8b4c-94b955bd94a9.png">  
input layer 에서 hidden layer로 cost가 감소되는 방향의 기울기를 가질 수 있도록 가중치를 학습시키는 것을 순전파(feedforward)라 한다. 그러나 순전파만으로 output layer에서 결과 를 뽑는다면 예상과 다른 오차가 발생한다. 이것을 줄여주기 위해 직전 레이어가 현재 레이어 에 미친 비율만큼 오차값을 나누어 직전 레이어에 전파하는 것이다.
쉽게 말하면, error 값을 거슬러 올라가며 전파하는 것을 의미한다.

## Training 세트와 Test 세트
결국 학습의 목적은 학습하지 않은 데이터에서도 잘 동작하는 제네럴한 성능을 가진 모델을 만드는 것이기 때문이다.  
1. Validation 세트가 따로 있는 이유는? 
학습시에 학습데이터에 오버피팅이 일어나고 있 지 않은지 판단하기 위해서.
2. Test 세트가 오염되었다는 말의 뜻은? 
모델이 테스트 데이터를 이미 학습해서 테스트 데이터의 객관성이 떨어졌다는 의미
3. Regularization이란 무엇인가? 
모델이 오버피팅이 되지 않고 범용성을 갖추도록 하는 기법이다. 일반적으로 드롭 아웃, L2 Regularization등이 있다. L2 Regularization은 일 반적으로 오버피팅이 특정 파라미터의 값이 커졌을 때 잘 일어난다고보고 loss값에 파 라미터의 제곱 크기를 더해주는 방법이다.
