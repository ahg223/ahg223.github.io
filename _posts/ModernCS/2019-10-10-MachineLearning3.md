---
title: "Machine Learning"
excerpt: "SVM, maive bayes, Association Rule, Gradient Descent, ML vs Static"

categories:
  - ModernCS
tags:
  - ModernCS
  - MachineLearning
---

## SVM의 차원을 확장 방식
->선형분류가 가능하도록 고차원공간으로 매핑 *SVM (Support Vector Machine): 초평면으
로 2개의 범주를 분류하는 이진 분류기이다.

## 나이브 베이즈(naive bayes)의 장점
단순하고 빠르며 매우 효과적이다. 노이즈와 결측 데이터가 있어도 잘 수행한다. 훈련에 대 한 상대적으로 적은 예제가 필요하지만 매우 많은 예제도 잘 수행한다. 예측에 대한 추정된 확률을 얻기 쉽다.  

나이브베이즈: P(label|data)==P(data|label)P(label)/P(data) -> ex)review내에 love, fantastic등의 단어가 등장하는 경우 P(positive|review)∝P(love|positive)×P(fantastic|positive)...

## Association Rule의 Support, Confidence, Lift
연관규칙: 특정 사건이 발생하였을 때 함께 (빈번하게) 발생하는 또 다른 사건의 규칙 
{맥주} - -> {기저귀} : 맥주를 사는 고객은 기저귀도 같이 산다   
{남성, 금요일, 맥주} --> {기저귀} : 금요 일에 맥주를 사는 남성 고객은 기저귀도 같이 산다  
(X,Y는 서로소 집합) X→Y:연관규칙 N: 전 체 사건의 수 n(X): 전체사건중 X를 포함하는 사건 수   지지도(support) s(X→Y) = X와 Y를 모 두 포함하는 사건 수 / 전체 사건 수 = n(X∪Y) / N   신뢰도(Confidence) c(X→Y) = X와 Y를 모 두 포함하는 사건 수 / X가 포함된 사건 수 = n(X∪Y) / n(X)  
향상도(Lift) = 연관규칙의 신뢰도/ 지지도 = c(X→Y) / s(Y) 항목집합 X가 주어지지 않았을 때의 항목집합 Y의 확률 대비 항목집 합 X가 주어졌을 대 항목집합 Y의 확률 증가 비율
다른말로 표현하자면, 향상도 가 1보다 크거나(+관계) 작다면(-관계) 우연적 기회(random chance)보다 우수함을 의미합니다. (X와 Y가 서로 독립이면 Lift = 1)

## Newton’s Method와 Gradient Descent
Newton's Method 방정식 f(x) = 0의 해를 근사적으로 찾을 때 사용되는 방법. 현재 x값에서 접선을 그리고 접선이 x축과 만나는 지점으로 x를 이동시켜 가면서 점진적으로 해를 찾아가 는 방법 초기값을 잘 주면 금방 해를 찾을 수 있지만 잘못 주면 시간이 오래 걸리거나 아예 해 를 찾지 못할 수 있다.  

Gradient Method f'(x)가 0이 되는 점을 찾는 방법 미분하여 극소점을 찾아가는 방법 (local minimum에 빠질수도 있다는 것이 문제점) 모든 차원과 모든 공간에서 적용이 가능 *뉴턴법 은 해를 찾는 수렴속도가 빠르고 해 근처에서 수렴속도가 급격히 느려지는 문제점이 없다. 반 면 gradient descent는 해에 근접할수록 기울기가 0에 가까워 지기 때문에 수렴속도가 느려 진다.   
최적화(optimization) 문제: 원하는 어떤 조건(함수값을 최소화 또는 최대화)을 만족시 키는 최적의 파라미터(변수) 값을 찾는 문제 카메라의 파라미터(초점거리 등)를 찾는 문제, 목 적지까지의 차량의 에너지(연료) 소모를 최소화하는 이동 경로를 찾는 문제 목적함수가 이윤, 점수(score) 등인 경우에는 최대화 문제, 비용(cost), 손실(loss), 에러(error) 등인 경우에 는 최소화 문제

## 머신러닝(machine)적 접근방법 통계(statistics)적 접근방법
머신러닝 -모형의 복잡성 보다는 과적합(overfitting)을 고려합니다. 머신러닝은 예측을 더욱 중시하기 때문에 모형의 과적합은 예측율를 저하시킵니다.  
머신러닝 -머신러닝은 기본적으로 알고리 즘을 사용하여 데이터를 분석 및 학습을 하고 그에 따른 판단이나 예측을 합니다. 따라서 궁 극적으로 의사결정 기준에 대한 구체적인 지침을 소프트웨어에 사람이 코딩하는 것이 아니 라 대량의 데이터와 알고리즘을 통해 컴퓨터가 데이터 그 자체를 학습하여 작업을 수행 방법 을 익하는 것을 목표로 합니다. 

통계 -모형의 복잡성보다 단순성을 추구합니다. 수학 방정식 의 형태로 변수들 간의 관계를 형식화합니다. 
통계 -인자(parameter)의 해석 가능성과 모델링 및 샘플링의 가정(assumption)을 강조합니다. 결과를 예측하기 위한 변수들 간의 관계성을 중 시하는 수학의 한 분야입니다. 추천 시스템을 대상으로 비유를 하면 머신러닝은 추천 결과의 정확도를 중시하는 반면 통계는 왜 이 상품을 추천해야 하는지 의미를 설명할 수 있습니다. 머신러닝은 통계처럼 결과에 대한 해석하는 부분이 부족합니다.
