---
title: "Data Statistics"
excerpt: "엔트로피, Information Gain, 빅데이터와 정규성 테스트, 모수적 비모수적 방법론, likelyhood vs probability"

categories:
  - ModernCS
tags:
  - ModernCS
  - DataScience
---

## 엔트로피(entropy)와 Information Gain
엔트로피란 어떤 데이터 셋에서 서로 다른 데이터가 얼마나 섞여있는지, 즉 불순도를 나타 내는 값입니다. (부연 설명: 0에서 1 사이의 값을 지니며 1에 가까울수록 불순도가 높음. 즉 0 일 경우 한 종류의 데이터만으로 이루어졌음을 의미). 어떤 데이터 셋 A에 대한 엔트로피는 다음과 같은 식으로 표현됩니다.  
<img width="449" alt="스크린샷 2019-11-14 오후 8 59 15" src="https://user-images.githubusercontent.com/34998051/68855465-9f879700-0721-11ea-8d82-068456510635.png">  

예를 들어서 데이터 셋 A에 총 16개의 데이터(   img )가 있고 그 중에 빨간색(범주 1)에 속 하는 데이터가 10개, 파란색(범주 2)에 속하는 데이터가 6개일 때 데이터 셋 A의 엔트로피는 다음과 같이 계산됩니다.  
<img width="449" alt="스크린샷 2019-11-14 오후 8 59 24" src="https://user-images.githubusercontent.com/34998051/68855478-a4e4e180-0721-11ea-93d4-002b50d244c6.png">  

정보획득(Infomation gain)이란 데이터 셋 A가 어떤 기준에 따라 분할되었을 때, 순도가 증가(또는 불확실성 감소), 다시 말해 엔트로피가 감소하는 것을 말합니다. 위의 데이터 셋 A를 예로 들자면 어떤 기준에 의해 A를 분할했을 때 첫 번째 그룹은 빨간색이 7개, 파란색이 1개, 두 번째 그룹은 빨간색이 3개, 파란색이 5개가 되었다고 가정했을 때 엔트로피 감소 양은  
<img width="449" alt="스크린샷 2019-11-14 오후 8 59 33" src="https://user-images.githubusercontent.com/34998051/68855489-aadac280-0721-11ea-8e42-2b794598cee0.png">  


0.20이 됩니다. 이 때 우리는 어떤 기준에 의해 A를 분할했을 때 0.2만큼 엔트로피가 감소(= 순도 증가=불순도 감소=정보획득)했다고 볼 수 있습니다.

## 빅데이터와 정규성 테스트
통계에서는 모집단에 대해 실질적으로 전수조사를 수행하기 어렵기 때문에 표본을 추출하여 표본 집단의 모수적 특징을 통해 모집단의 모수적 특징을 파악하곤 합니다. 이 때 이러한 모 수적 방법론의 상당수가 데이터가 정규 분포를 따른다고 가정하기 때문에 정규성 검정을 통 하여 정규 분포를 따르는지 확인할 필요가 있습니다.
그러나 데이터의 수가 많을 경우 표본을 충분한 크기로 추출할 수 있고 이 경우 중심극한정리 에 의해 표본평균의 분포가 정규성 검정 없이도 정규 분포를 따른다고 볼 수 있기 때문에 이 런 경우 정규성 검정을 생략하기도 합니다. 따라서 엄밀하게 말하자면 정규성 검정이 필요하 나 중심극한정리에 의해 이미 정규분포를 따른다는 것을 알기 때문에 데이터가 많은 경우 정 규성 검정을 생략한다고 생각합니다. 

## 모수적 방법론 vs 비모수적 방법론
통계에서 사용하는 많은 모수적 방법론들은 데이터가 정규 분포를 따른다는 가정 하에 쓰입니다. 때문에 정규성 검정을 통해 정규 분포를 따르는지 확인하는 과정이 필요합니다. 만약 정규 분포를 따르는 것이 확인이 되었다면 모수적 방법론을 쓸 수 있지만 정규 분포를 따르지 않는다면 비모수적 방법론을 쓸 수 있다고 볼 수 있겠습니다.
 
## “likelihood”와 “probability”의 차이
이산 값에 대한 확률(probability)은 직관적으로 쉽게 구해집니다. 예를 들어 어떤 공간 안에 1부터 6까지의 자연수가 한 개씩 들어있을 때, 여기서 숫자를 하나 꺼낸다면 모든 숫자의 경우 꺼내질 확률이 1/6로 동일합니다. (꽤나 쉽고 직관적으로 구해집니다.)  

그러나 연속적인 값에 대해서는 모든 확률이 0이 되어버립니다. 예를 들어 어떤 공간 안에 1 부터 6까지의 실수가 한 개씩 들어있을 때, 여기서 숫자를 하나 꺼낸다면, 1부터 6까지 존재 하는 실수의 개수가 무한하기 때문에 어떤 숫자든 꺼내질 확률이 0에 가까워져버립니다. 따 라서 이럴 경우 특정 사건에 대한 확률 값을 말하는 것은 의미가 없습니다. 대신에 우리는 1 에서2사이에 존재하는 값을 뽑을 확률은 1/6 이라고 말할 수 있습니다.  

이 때 1에서 2 사이의 값에 대한 확률 1/6을 확률 밀도 함수에서 보면, 1에서 2 구간 사이의 그 래프 아래의 넓이라고 볼 수 있습니다(넓이의 값이 1/6).  

연속사건의 경우 분명 특정 사건이 일어날 어떤 가능성이 있을 것 같은데 이를 확률 값으로 표현할 수는 없습니다. 이 때 특정 사건이 일어날 가능성을 (0으로 수렴하는)확률 대신 가능도(또는 우도, likelihood)로 표현하며 이는 특정 위치에서의 확률 밀도 함수의 값이 됩니다.  

이산 값에 대한 likelihood는 확률 값과 동일하지만 연속 값에 대한 likelihood는 확률 값과 다릅니다.  
